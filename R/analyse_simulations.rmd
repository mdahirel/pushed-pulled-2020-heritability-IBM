---
title: 'Pushed expansions and sources of variation- individual-based model, data analysis'
author: "Maxime Dahirel & Chlo√© Guicharnaud"
date:
output:
  html_document:
    theme: yeti
    toc: TRUE
    toc_float: TRUE
    code_download: TRUE
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, eval = FALSE)
```

```{r load-packages}
library(nlrx)
library(arm)
library(matrixStats)
library(tidyverse)
library(mgcv)
library(gratia)
library(cowplot)

library(arm)
library(cmdstanr)
#set_cmdstan_path("C:/Users/Maxime/Documents/.cmdstanr/cmdstan-2.26.0")
library(brms)
options(mc.cores=2)

library(here)
```

discussion thread to follow:
sources of evo available as constraints
compatibility between "yes, evo favours mostly DID over the range" BUT "still DDD+ over all, so still open to pushiness, especially if dmax increase", despite apparent paradox
general result still loss of pushiness in many cases, but only if genet div in matching traits (vs enhancing traits)
dispersal costs and heritability influence the dynamics
the DDD+ to DDD- pattern seen in a few studies is not recovered here (well it is, but not in a systematic way)
what's missing? obvious answer: evolution of life history, trade-offs...

# Introduction

```{r}
data <- read_csv(here("NetLogo_output","model-output.csv"))
```

<!--the classical result that costs = more DDD was in contexts where dmax and midpoint did not evolve-->
<!-- hyper important to understand eco-evo dynamics: check that N=0 cells within pops are not deleted-->

<!--key thing to do, check that the effect of absolute slope on speed/diversity is the same independently of source of variation (dmax only, matching only, both) or else difficult to compare their evol dynamics-->


```{r}
test<-data %>% 
  mutate(is.VP_dmax=as.numeric(VP_logit_dmax >0),
           is.VP_DDD=as.numeric(VP_slope >0)) %>% 
  mutate(mortality=factor(dispersal_mortality)) %>% 
  mutate(is.evo=as.numeric(heritability>0)) %>% 
  group_by(replicateID,ticks) %>% 
  mutate(front_0=max(pxcor*(N_allele0_post>0)),
         front_1=max(pxcor*(N_allele1_post>0))) %>% 
  filter(pxcor == present_front-5 ) %>%  # higher N so less noise than front - 1, so estimates of mean more accurate
  mutate(front_lag=min(c(front_0,front_1)),
         front=max(c(front_0,front_1))) %>% 
  ungroup() %>% 
    filter(ticks==120) %>% 
  mutate(vartype=factor(paste("vP",is.VP_DDD>0 |is.VP_dmax>0,
                              "h",heritability)))


mod=glm(cbind(front,ticks-front)~(scale(mean_d0)+scale(mean_avgslope0_K))*mortality,family=binomial,data=test)
## very basic: ignore possible effects of sources of variances

mod_div=glm(cbind(front_lag,front-front_lag)~(scale(mean_d0)+scale(mean_avgslope0_K))*mortality,family=binomial,data=test)
## justification: se e.g. roques 2012 for the idea that in (more) pushed expansions, speed of one fraction = to speed of whole expansion, + distance to fixation = integrator of time to fixation

#gam version?
mod=gam(cbind(front,ticks-front)~s(mean_d0, by = mortality,k=10)+s(mean_avgslope0_K,by=mortality,k=10)+mortality,
        family=binomial,data=test,method="REML")

mod_div=gam(cbind(front_lag_100,front_100-front_lag_100)~s(mean_d0_100, by = mortality)+s(mean_avgslope0_K_100,by=mortality)+mortality,
        family=binomial,data=test,method="REML")

gam.check(mod) #
draw(mod)
appraise(mod)

# bayesian versions (use penalising priors? spike and slab?)
mod=brm(front|trials(ticks)~ (scale(mean_d0_100)+scale(mean_avgslope0_K_100))*mortality,
        data=test,family=binomial,
        chains=4,iter=2000,warmup=1000,
        prior=c(set_prior("normal(0,1)",class="Intercept"),
                set_prior("normal(0,1)",class="b")),
        seed=42,backend = "cmdstanr")



mod_div=brm(front_lag_100|trials(front_100)~ (scale(mean_d0_100)+scale(mean_avgslope0_K_100))*mortality,
        data=test,family=binomial,
        chains=4,iter=2000,warmup=1000,
        prior=c(set_prior("normal(0,1)",class="Intercept"),
                set_prior("normal(0,1)",class="b")),
        seed=42,backend = "cmdstanr")


# use of beta-binomial maybe more appropriate? but would need to use rstan at least in the expose function stage
```


```{r}
data %>% 
  mutate(is.VP_dmax=as.numeric(VP_logit_dmax >0),
           is.VP_DDD=as.numeric(VP_slope >0)) %>% 
  mutate(mortality=factor(dispersal_mortality)) %>% 
  mutate(is.evo=as.numeric(heritability>0)) %>% 
  group_by(replicateID,ticks) %>% 
  mutate(front_0=max(pxcor*(N_allele0_post>0)),
         front_1=max(pxcor*(N_allele1_post>0))) %>% 
  filter(pxcor == present_front-5 ) %>%  # higher N so less noise than front - 1, so estimates of mean more accurate
  mutate(front_lag=min(c(front_0,front_1)),
         front=max(c(front_0,front_1))) %>% 
  ungroup() %>% 
  group_by(replicateID) %>% 
  arrange(ticks) %>% 
  ungroup() %>% 
  ggplot()+
  geom_line(aes(ticks,mean_midpoint,group=replicateID,col=ticks))+
  facet_grid(rows=vars(dispersal_mortality,VP_logit_dmax>0),
               cols=vars(heritability,VP_slope>0))
```



```{r}
data %>% filter(pxcor==present_front-1 & slope_start==-6) %>% 
  ggplot() +
  geom_boxplot(aes(factor(ticks),present_front,col=factor(midpoint_start)))+
    facet_grid(rows=vars(dispersal_mortality,VP_logit_dmax>0),
               cols=vars(heritability,VP_slope>0))
```
seems like there's an excess of stochasticity whenever negative start slope+ start midpoint=0 + no variation in slope. Makes sense, those are conditions that set dK_virtually 0. How to account?

```{r}

test2<-data %>% 
  mutate(is.VP_dmax=as.numeric(VP_logit_dmax >0),
           is.VP_DDD=as.numeric(VP_slope >0)) %>% 
  mutate(is.evo=as.numeric(heritability>0)) %>% 
  filter(pxcor == present_front - 5 ) %>%  # higher N so less noise than front - 1, so estimates of mean more accurate
  filter(ticks==120) %>% 
  select(is.VP_DDD,is.VP_dmax,
         mean_avgslope0_K,
         VP_slope,VP_midpoint,VP_logit_dmax,mean_dmax,
         dispersal_mortality,
         heritability,
         replicateID,seedID,
         slope_start,midpoint_start) %>%  
  mutate(rnorm_slope_start=map2(.x=slope_start,.y=sqrt(VP_slope),.f=~rnorm(10000,.x,.y))) %>% 
  mutate(rnorm_midpoint_start=map2(.x=midpoint_start,.y=sqrt(VP_midpoint),.f=~rnorm(10000,.x,.y))) %>% 
  mutate(rnorm_dmax_start=map2(.x=0,.y=sqrt(VP_logit_dmax),.f=~rnorm(10000,.x,.y) %>% invlogit())) %>% 
  mutate(rnorm_function_start0=map2(.x=rnorm_slope_start,.y=rnorm_midpoint_start,
                                    .f=function(.x,.y){
                                      1/(1+exp(-.x*(0-.y)))
                                    })) %>% 
  mutate(rnorm_function_start0=map2(.x=rnorm_dmax_start,.y=rnorm_function_start0,
                                    .f=function(.x,.y){
                                      .x*.y
                                    }))%>% 
  mutate(rnorm_function_startK=map2(.x=rnorm_slope_start,.y=rnorm_midpoint_start,
                                    .f=function(.x,.y){
                                      1/(1+exp(-.x*(1-.y)))
                                    })) %>% 
  mutate(rnorm_function_startK=map2(.x=rnorm_dmax_start,.y=rnorm_function_startK,
                                    .f=function(.x,.y){
                                      .x*.y
                                    })) %>% 
  mutate(start_avgslope=map2(.x=rnorm_function_startK,.y=rnorm_function_start0,
                             .f=function(.x,.y){
                               mean((.x-.y)) ##arrange to keep K and code it correctly
                             })) %>% 
  unnest(start_avgslope) %>% 
  mutate(start_avgslope=start_avgslope,
         mean_avgslope0_K=mean_avgslope0_K)

 
  ggplot(test2)+
  geom_abline(intercept = 0,slope=1,lty=2)+
  geom_point(aes(start_avgslope,mean_avgslope0_K))+
  geom_smooth(aes(start_avgslope,mean_avgslope0_K),method="lm")+
  facet_grid(rows=vars(dispersal_mortality,is.VP_dmax),
                       cols=vars(heritability,is.VP_DDD))+ 
  scale_x_continuous("original mean absolute slope",limits = c(-1,1))+
  scale_y_continuous("final mean absolute slope",limits = c(-1,1))
```


```{r}
mod<-brm(bf(
  mean_avgslope0_K~intercept+slope*start_avgslope,
  intercept~heritability+is.VP_dmax*is.VP_DDD+dispersal_mortality,
  slope~heritability+is.VP_dmax*is.VP_DDD+dispersal_mortality,
  sigma~heritability+is.VP_dmax+is.VP_DDD+dispersal_mortality,
  nl=TRUE),
  data=test2,
  chains=4,iter=4000,warmup=2000,
  prior=c(
    set_prior("normal(0,1)",class="b",nlpar=c("intercept","slope")),
    set_prior("normal(0,1)",dpar="sigma")
  ),
  seed=42,backend="cmdstanr"
)
```



Ok it looks like we find the costs+ = ddd++ pattern only when dmax is not allowed to evolve (makes sense, wasn't allowed to in the models that showed this, iirc). But with dmax allowed to evolved, things are more messy


prediction from birzu: pulled waves favour evolution of strats with higher dispersal rate at the edge
can't look at the dispersal function, since N at the edge varies bw types, need to look at actual dispersal events
```{r}
data %>% 
  mutate(is.VP_dmax=VP_logit_dmax >0,
         is.VP_DDD=VP_slope >0) %>% 
  filter(ticks==100 & pxcor ==(present_front -1)) %>% 
  ggplot()+
  geom_boxplot(aes(factor(slope_start),1-N_sedentary/(N_predispersal),col=factor(midpoint_start)))+
  facet_grid(rows=vars(dispersal_mortality,is.VP_dmax),
                       cols=vars(heritability,is.VP_DDD))+
  geom_hline(yintercept = 0)
```
mmm... mayyyybe? but very dependent on what pxcor we whoose (front-1, front -2...), because N varies quickly. potentially interesting to look at d=f(distance from front)



